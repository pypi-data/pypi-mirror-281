Metadata-Version: 2.1
Name: unofficial_ffm_openai
Version: 0.2.1
Summary: An unofficial Formosa Foundation Model API client implementation compatible with LangChain and OpenAI
Author-email: derekhsu <derekhsu@hotmail.com>
License: MIT License
        
        Copyright (c) 2024 Derek Hsu
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://github.com/derekhsu/unoffcial_ffm_openai_client
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: langchain-openai
Requires-Dist: langchain-core
Requires-Dist: langchain
Requires-Dist: openai>=1.23.3

# unofficial_ffm_openai_client
An unofficial Formosa Foundation Model client implementation based on OpenAI and LangChain

## Introduction

This is an unofficial Python client implementation for the Formosa Foundation Model public endpoint, compatible with the OpenAI Python client and LangChain. Currently, it only implements the [Conversation API](https://docs.twcc.ai/docs/user-guides/twcc/afs/afs-modelspace/api-and-parameters/conversation-api) and supports the public endpoint. Note that the synchronous API is not yet implemented.

# Changelog

- 0.2.1 - [fix] Remove unnecessary import from `chat_completion.py`
- 0.2.0 
  - Add a callback for counting token consumption in streaming and non-streaming mode.
  - Add json error handling for sync streaming mode.
  - Add token consumption info in the result of streaming and non-streaming mode.
- 0.1.3 - Support function calls.
- 0.1.2 - Support embeddings.

## Usage

Install using pypi:

```shell
pip install unofficial-ffm-openai
```

You can use it similarly to the original OpenAIChat, with a few different parameters:

```python
from ffm.langchain.language_models.ffm import FfmChatOpenAI

chat_ffm = FfmChatOpenAI(
    ffm_endpoint="https://api-ams.twcc.ai/api",
    max_tokens=1000,
    temperature=0.5,
    top_k=50,
    top_p=1.0,
    frequency_penalty=1.0,
    ffm_api_key="your key",
    ffm_deployment="ffm-mistral-7b-32k-instruct",  # or other model name
    streaming=True,
    callbacks=callbacks
)
```

```python
from ffm.embeddings import FFMEmbeddings

embedding = FFMEmbeddings(
    base_url="",
    api_key="your key")
```

### Callbacks

You cen use the ffm callbacks as using other callbacks such as openai callback, here is the example:

```python
from ffm.langchain.callbacks import get_ffm_callback

with get_ffm_callback() as cb:
    ...do something using llm...
    
    total_tokens = cb.total_tokens
    prompt_tokens = cb.prompt_tokens
    completion_tokens = cb.completion_tokens
    successful_requests = cb.successful_requests
```

* Note: Cost calculation has not been done yet but is in progress.

## Limitation

Currently, it has only been tested with the following dependencies:

```
langchain                         0.1.20
langchain-community               0.0.38
langchain-core                    0.1.52
langchain-openai                  0.1.7
langchain-text-splitters          0.0.2
langchainhub                      0.1.15
```

and the OpenAI client:

```
openai                            1.30.1
```

## TODO

* Full implementation for the synchronous API.
