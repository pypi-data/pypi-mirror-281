# llaminate

Optimized version of [llama3][github-llama3], using [tokun][github-tokun].

This project is a showcase for a new tokenization technique.
It uses a NN model to compress the whole Unicode space into tokens.

## Resources

### Models

### Notebooks

## TODO

See [TODO](TODO.md).

## Credits

This project winks at [llama3 from Meta][github-llama3], but doesn't actually its weights nor code.

## License

Licensed under the [aGPLv3](LICENSE.md).

[github-llama3]: https://github.com/meta-llama/llama3
[github-tokun]: https://github.com/apehex/tokun
